---
---
title: "Gas Consumption in California"
author: "Elena"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## About this project

This R Markdown notebook explores and forecasts monthly residential natural gas consumption in California using ARIMA and SARIMA models.


```{r libraries}
library(ggplot2)
library(patchwork)
library(forecast)
library(tseries)
library(urca)
library(DescTools)
library(dplyr)
library(FinTS)
library(fUnitRoots)
library(TSA)
```

## Dataset description
The dataset used in this project contains **monthly residential natural gas consumption** in the state of **California**, measured in **Million Cubic Feet**. It is sourced from the [U.S. Energy Information Administration (EIA)](https://www.eia.gov/dnav/ng/hist/n3010ca2m.htm).

- **Time period covered:** January 1989 to January 2024  
- **Frequency:** Monthly  
- **Total observations:** 421 time points  
- **Measurement unit:** Million Cubic Feet (MCF) of natural gas consumed  
- **Missing values:** One missing value in January 2024 (imputed with the historical January average)

This dataset is ideal for time series analysis, as it is regularly spaced (monthly) and spans over three decades, capturing both seasonal and long-term consumption patterns.

```{r import}
gas <- read.csv('California_Natural_Gas_Residential_Consumption.csv', skip = 4)
gas$Month <- as.Date(paste0(gas$Month, "-01"), format = "%b %Y-%d")
colnames(gas)[2] <- "cu_ft"
gas <- gas %>% mutate(Date = format(Month, "%Y-%m"))
gas <- gas %>% arrange(Month)
head(gas)
```
# Data Cleaning and Imputation
```{r cleaning}
january_mean <- gas %>% filter(format(Month, "%m") == "01") %>% summarise(mean = mean(cu_ft, na.rm = TRUE)) %>% pull(mean)
gas <- gas %>% mutate(cu_ft = ifelse(format(Month, "%Y-%m") == "2024-01" & is.na(cu_ft), january_mean, cu_ft))
```
# EDA
In this section, we conduct an initial exploration of the gas consumption time series. We need to understand the distribution, variability, and potential trends in the data before applying forecasting models. First, we prepare a statistics summary and build a line plot. 
the dataset shows significant variability in the gas consumption pattern. The mean is higher than the median indicating that the distriution is right-skewed. the spread between the 1st and the 3d quartile is wide (IQR=30,936), meaning there is a significant seasonal/monthly variation. This variability prompts us to conduct seasonality analysis, stationarity tests, log-transformation if modeling requires/assumes homoscedasticity. 

```{r}
summary(gas$cu_ft)

ggplot(gas, aes(x = Month, y = cu_ft)) +
  geom_line() +
  stat_smooth(colour = "red") +
  ggtitle("Time Series of Gas Consumption")
```
We build histogram and qq-plot to see the features the numbers alone may miss:
- in the histogram we see that our data have 2 peaks
- qq-plot shows that the data deviates from normality at the lower left and upper right corners. deviation in the lower left corner is more pronounced meaning unusually low gas consumption values are more frequent than expected under normality.
```{r hist qqplot, echo = FALSE}
p1 <- ggplot(gas, aes(x = cu_ft)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  geom_density(alpha = 0.6, color = "blue") +
  ggtitle("Histogram and Density")

p2 <- ggplot(gas, aes(sample = cu_ft)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  ggtitle("Q-Q Plot")

p1 + p2
```
# Distribution and Stationarity Tests
- moderate positive skew 0.73 suggests that while most months have average gas use, there are also occasional high-usage months
- the data distribution is platykurtic (flatter than normal), we have fewer extreme values than a normal distribution
The distribution here is roughly symmetric without heavy tails. It means data transformations are optional. They still may help stabilize variance.
- according to the ttest result, the mean is different from 0. The confidence interval does not include 0 meaning the mean usage is significantly greater than 0.
- ADF test checks if the data stationary/non-stationary. The null hypothesis (H0) is that the series is non-stationary. In this case p-value<0.05, hence we reject the H0 hypothesis. This series is stationary.
- KPSS test also checks if the data stationary or not. The null hypothesis (H0) is that the series is stationary. In this case p-value>0.05, hence we fail to reject the H0 hypothesis. This series is stationary. 

```{r distribution and stationarity tests}
Skew(gas$cu_ft)
Kurt(gas$cu_ft)
t.test(gas$cu_ft)
adf.test(gas$cu_ft)
kpss.test(gas$cu_ft)
```
# Log-Transformation and Decomposition
Now we apply log-transformation to make the variance more constant. After that we can perform seasonal decomposition
The decomposition plot consists of 4 parts:
- original data - even here we can see the seasonality
- seasonal part where we see peaks and troughs and constant shape meaning the seasonal behavior is consistent over time. It is an ideal pattern for SARIMA model.
- trend part where we see a gradual decrease
- remainder part, in other words, what's left after removing trend and seasonality. It looks like white noise, no clear pattern.   
```{r log-transform}
gas_log <- gas %>% mutate(cu_ft = log(cu_ft))
gas_ts <- ts(gas_log$cu_ft, frequency = 12, start = c(1989, 1))

decomp <- stl(gas_ts, s.window = "periodic")
plot(decomp)
```
## ACF/PACF plots
**ACF plot** shows a wave-like pattern. It's a classic autocorrelation pattern suggesting a seasonal structure.
**PACF** We see gradually shrinking spikes. It means that though AR terms are at play, their effect diminishes over time.
```{r ACF/PACF}
library(forecast)
library(ggplot2)
library(patchwork)  # For arranging ggplots

# Log-transformed time series
p_acf <- ggAcf(gas_ts, lag.max = 24) +
  ggtitle("ACF of Log-Transf Gas Cons-n") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

p_pacf <- ggPacf(gas_ts, lag.max = 24) +
  ggtitle("PACF of Log-Transf Gas Cons-n") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# Combine with patchwork
p_acf + p_pacf
```

## Splitting into Train and Test
Here we split the dataset into train and test subsets.
```{r train/test split}
train_size <- floor(0.8 * length(gas_ts))
train <- window(gas_ts, end = c(1989 + (train_size - 1) %/% 12, (train_size - 1) %% 12 + 1))
test <- window(gas_ts, start = c(1989 + train_size %/% 12, train_size %% 12 + 1))
```
# Modeling
To prepare an accurate forecast, we need to try different models and compare different approaches. Taking into consideration the data we have, we are going to build 3 models. Each model has its strengths.
**ARIMA** captures autocorrelation (AR), trends (I), and short-term shocks (MA). It works well on stationary data, it does not account for seasonality.
**SARIMA** is an ARIMA extension. It explicitly models seasonal patterns. We guess this model is the best one for our data.
**ETS** models the components of time series (trend, seasonality, and error) using exponential smoothing. This model works well when the seasonality is stable, its strength is that unlike ARIMA/SARIMA, it does not require stationarity.
## Auto-ARIMA
We built the ARIMA model and prepared a forecast.
- Error metrics are low
- ACF1=-0.017 meaning little correlation left in residuals. However, it tests autocorrelation only at lag 1. 
- Ljung-Box test checks if there is autocorrelation at multiple lags simultaneously. Ljung-Box p-value<0.05. Hence, we reject H0 hypothesis that residuals are randomly distributed. The autocorrelation hasn't been fully captured by the model.
- Mcleod-Li test checks for autocorrelation in squared residuals. 9 out of 20 lags had p-values below the 0.05 threshold. There is heteroscedasticity in the residuals.

Conclusion: A more complex model which includes seasonal components is needed.
```{r auto-arima}
basic_arima <- auto.arima(train, seasonal = FALSE)
summary(basic_arima)
checkresiduals(basic_arima)
McLeod.Li.test(y = residuals(basic_arima), gof.lag = 20)
forecast(basic_arima, h = length(test)) %>% autoplot()
```
## Auto-SARIMA
This time we build a SARIMA. It captures both the short-term structure and seasonal pattern.
- smaller errors mean SARIMA outperforms ARIMA
- AIC and BIC are lower than AIC and BIC of ARIMA models meaning better fit
- Ljung-Box test: p-value>0.05. We fail to reject H0 hypothesis that there is no significant correlation left in the residuals. 
- This time McLeod-Li test demonstrated a better result: 4 out of 20 lags had p-values below the 0.05 threshold. There is mild heteroscedasticity in the residuals, the residuals variance is mostly stable. It means that the model's assumptions are generally satisfied
```{r auto-sarima}
auto_model <- auto.arima(train)
summary(auto_model)
checkresiduals(auto_model)
McLeod.Li.test(y = residuals(auto_model), gof.lag = 20)
```
```{r}
forecast(auto_model, h = length(test)) %>% autoplot()
```
## SARIMA with Grid-Search
This time we set stepwise=FALSE. The algorithm will search all combinations of (p,d,q)(P,D,Q). What we get here:
- slightly lower errors
- slightly lower AIC/BIC 
- Ljung-Box p>0.05, residuals look like white moise
- Mcleod-Li test results looks very much the same as for auto-SARIMA model. The heteroscedasticity is mild and the model assumptions are satisfied. 
```{r SARIMA with grid-search}
gs_model <- auto.arima(train, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)
summary(gs_model)
checkresiduals(gs_model)
McLeod.Li.test(y = residuals(gs_model), gof.lag = 20)
forecast(gs_model, h = length(test)) %>% autoplot()
```
## ETS Model
We will also try ETS model:
- MAE and MAPE are higher than the best SARIMA model
- Ljung-Box has p-value<0.05. It's a strong evidence of residual autocorrelation. 
```{r ets}
ets_model <- ets(train)
summary(ets_model)
checkresiduals(ets_model)
forecast(ets_model, h = length(test)) %>% autoplot()
```
#Model Comparison
```{r comparison}
# Generate forecasts
fc_auto_arima <- forecast(basic_arima, h = length(test))
fc_auto_sarima <- forecast(auto_model, h = length(test))
fc_grid_sarima <- forecast(gs_model, h = length(test))
fc_ets        <- forecast(ets_model, h = length(test))
```

```{r}

# Accuracy metrics
acc_auto_arima <- accuracy(fc_auto_arima, test)
acc_auto_sarima <- accuracy(fc_auto_sarima, test)
acc_grid_sarima <- accuracy(fc_grid_sarima, test)
acc_ets        <- accuracy(fc_ets, test)

```
```{r}
comparison <- data.frame(
  Model = c("Auto ARIMA", "Auto SARIMA", "Grid SARIMA", "ETS"),
  RMSE  = c(acc_auto_arima["Test set", "RMSE"],
            acc_auto_sarima["Test set", "RMSE"],
            acc_grid_sarima["Test set", "RMSE"],
            acc_ets["Test set", "RMSE"]),
  MAE   = c(acc_auto_arima["Test set", "MAE"],
            acc_auto_sarima["Test set", "MAE"],
            acc_grid_sarima["Test set", "MAE"],
            acc_ets["Test set", "MAE"]),
  MAPE  = c(acc_auto_arima["Test set", "MAPE"],
            acc_auto_sarima["Test set", "MAPE"],
            acc_grid_sarima["Test set", "MAPE"],
            acc_ets["Test set", "MAPE"])
)
knitr::kable(comparison, caption = "Forecast Accuracy Comparison")

```
```{r}
autoplot(test, series = "Test Data") +
  autolayer(fc_auto_arima$mean, series = "Auto ARIMA") +
  autolayer(fc_auto_sarima$mean, series = "Auto SARIMA") +
  autolayer(fc_grid_sarima$mean, series = "Grid SARIMA") +
  autolayer(fc_ets$mean, series = "ETS") +
  ggtitle("Forecast Comparison") +
  ylab("Log Gas Consumption") +
  theme_minimal()

```
# Conclusion:
This notebook explored different time series models for forecasting California’s residential gas consumption. The SARIMA models demonstrated good residual behavior and forecast accuracy. Future enhancements could include weather variables and comparison with machine learning models.
